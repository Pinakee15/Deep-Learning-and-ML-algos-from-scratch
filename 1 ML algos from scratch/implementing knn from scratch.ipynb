{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementation of KNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x  = pd.DataFrame( data = iris['data'],columns = ['sl','sw','pl','pw'])\n",
    "y = iris['target']\n",
    "# Normalize the x \n",
    "transformer  = Normalizer()\n",
    "x = transformer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test ,y_train, y_test =  train_test_split(x, y , test_size = 0.2,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode([1,1,0]).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the KNN\n",
    "\n",
    "def euclidian_distance(a,b):\n",
    "    distance = 0\n",
    "    for i in range(len(a)):\n",
    "        distance = np.square(a[i] - b[i]) +distance\n",
    "    distance = np.sqrt(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(test_instance , training_data , training_label , k):\n",
    "    distances = []\n",
    "    \n",
    "    for index in range(len(training_data)):\n",
    "        distance_info = (training_label[index] , euclidian_distance(training_data[index] , test_instance))\n",
    "        distances.append(distance_info)\n",
    "    distances = sorted(distances , key = lambda k : k[1])\n",
    "    top_k_labels = [label[0] for label in distances[0:k]]\n",
    "    label = mode(top_k_labels).mode[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN(x_test[17] , x_train , y_train , 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Implementation of logistic regression from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "x, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "iterations = 36000\n",
    "intercept = 0\n",
    "weights = np.zeros_like(x_train[0])\n",
    "lamda = 0\n",
    "N = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x , weights , intercept):\n",
    "    return 1/(1 + np.exp(-((intercept + np.dot(weights, x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(z , x , y ):\n",
    "    gradient = (y - sigmoid(x , weights , intercept)) \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gradient_descent(gradient):\n",
    "#    weights = weights + leaning_rate*gradient\n",
    "#    intercept = intercept + learning_rate*()\n",
    "#    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36000/36000 [00:00<00:00, 41149.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(iterations)):\n",
    "    z = sigmoid(x[i] , weights , intercept)\n",
    "    gradient = calculate_gradient( z , x_train[i] , y[i])\n",
    "    weights = weights + learning_rate*x[i]*(gradient - (lamda*weights)/N)\n",
    "    intercept = intercept + learning_rate*gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13905745,  0.42572788,  0.46469008,  0.71064658,  0.28259081,\n",
       "        1.14624626, -1.1195814 , -0.26880231,  1.46189023,  0.03784674,\n",
       "       -0.08143955,  0.31358978,  0.37034735,  0.74001357,  0.56322186])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3753332212297188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(w,b, x):\n",
    "    N = len(x)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w , b, x[i]) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "#print(1-np.sum(y_train - pred(w,b,x_train))/len(X_train))\n",
    "#print(1-np.sum(y_test  - pred(w,b,x_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred(weights , intercept , x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73648"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Yet another way of doing it folks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:02<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "import math\n",
    "\n",
    "train_loss=[]\n",
    "test_loss=[]\n",
    "epochs=100\n",
    "eta0 = 0.0001\n",
    "alpha = 0.0001\n",
    "w = np.zeros_like(x_train[0])\n",
    "b= 0\n",
    "\n",
    "def sigmoid(w,x,b):\n",
    "    return 1/(1+np.exp(-(np.dot(x,w)+b)))\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    for batch in range(N):\n",
    "        \n",
    "        #batch = np.random.choice(len(x_train))\n",
    "\n",
    "        w = ((1-((eta0*alpha)/N)) * w)+((alpha*x_train[batch])*(y_train[batch]-sigmoid(w,x_train[batch],b)))\n",
    "\n",
    "        \n",
    "        b=b+eta0*(y_train[batch]-sigmoid(w,x_train[batch],b))\n",
    "\n",
    "    ytrain_pred=sigmoid(w,x_train,b)\n",
    "    ytest_pred=sigmoid(w,x_test,b) \n",
    "    Train_loss=0\n",
    "    Test_loss=0\n",
    "    \n",
    "    for a in range(len(x_train)): \n",
    "        Train_loss+=-((y_train[a]*(math.log(ytrain_pred[a])))+ ((1-y_train[a])*(math.log(1-ytrain_pred[a]))))\n",
    "    Normalized_train_loss=(Train_loss)/N\n",
    "    train_loss.append(Normalized_train_loss)\n",
    "    \n",
    "    \n",
    "    for c in range(len(x_test)):      \n",
    "        Test_loss+=-((y_test[c]*(math.log(ytest_pred[c])))+ ((1-y_test[c])*(math.log(1-ytest_pred[c])))) \n",
    "    Normalized_test_loss=(Test_loss)/len(y_test)\n",
    "    test_loss.append(Normalized_test_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"NORM Train loss :\",Normalized_train_loss)\n",
    "    #print('NORM test loss :',Normalized_test_loss)\n",
    "    \n",
    "    #print('epoch {}'.format(i),'\\ntrain _loss:',Train_loss)\n",
    "    #print('epoch {}'.format(i),'\\ntest _loss:',Test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.29756022e-01,  1.93023835e-01, -1.48464492e-01,  3.38103414e-01,\n",
       "       -2.21229065e-01,  5.69932661e-01, -4.45183637e-01, -8.99209544e-02,\n",
       "        2.21804886e-01,  1.73809503e-01,  1.98727752e-01, -5.59489815e-04,\n",
       "       -8.13106734e-02,  3.39094300e-01,  2.29785009e-02])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8930132160174784"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len([x for x in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  My new approach friends to solve this now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 15)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001   # This will be the learining rate of the gradient descent \n",
    "intercept = 0\n",
    "weights = np.zeros_like(x_train[0])\n",
    "lamda = 0.0001   # this is the constant we use with the regulariser\n",
    "iterations = 300\n",
    "N = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(weights , intercept, x):\n",
    "    return 1/(1 + np.exp(-(np.dot(weights,x) + intercept)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961423254056835"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([x for x in range(4)]), 0.1 , [np.random.rand() for x in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:58<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# here we will iterate and constantly update the weights and the intercept\n",
    "for i in tqdm(range(iterations)):\n",
    "    for batch_index in range(N):\n",
    "        #batch_index = np.random.randint(0,N)\n",
    "        weights = (1 - alpha*lamda/N)*weights + alpha*x_train[batch_index]*(y[batch_index] - sigmoid(weights,intercept,x[batch_index]))\n",
    "        intercept = intercept +alpha*(y[batch_index] - sigmoid(weights,intercept,x[batch_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.58703486, -3.43977361,  2.48557237,  6.3279082 ,  2.25036457,\n",
       "        5.92522705, -4.37834416, -4.12770115,  1.55107821, -0.45223257,\n",
       "       -0.20733484,  4.17269546,  2.97894235, -1.00659106, 10.17721666])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.352551303734417"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred(weights , intercept , x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69864"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the log loss of the results given by our model\n",
    "def compute_log_loss(weigts , intercept , predicted_y , y_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y*log(prediction) - (1-y)*log(1-prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
